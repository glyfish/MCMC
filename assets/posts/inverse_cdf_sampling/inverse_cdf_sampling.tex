\documentclass[12pt]{article}
\usepackage[pdftex,pagebackref,colorlinks=true,pdfpagemode=none,urlcolor=blue,linkcolor=blue,citecolor=blue,pdfstartview=FitH]{hyperref}

\usepackage{amsmath,amsfonts}
\usepackage{graphicx}
\usepackage{color}
\usepackage{hyperref}
\usepackage{minted}
\usemintedstyle{bw}

\newcommand{\homedir}{\string~}

\setlength{\oddsidemargin}{0pt}
\setlength{\evensidemargin}{0pt}
\setlength{\textwidth}{6.0in}
\setlength{\topmargin}{0in}
\setlength{\textheight}{8.5in}

\setlength{\parindent}{0in}
\setlength{\parskip}{5px}

\input{\homedir/Develop/python/gly.fish/latex2wp/macrosblog.tex}

\title{Inverse CDF Sampling}
\author{Troy Stribling}


\begin{document}

% ------------------------------------------------------------------------------------------------
% Introduction
% ------------------------------------------------------------------------------------------------
\iftex
\maketitle
\section{Introduction}
\fi

Inverse \href{https://en.wikipedia.org/wiki/Cumulative_distribution_function}{CDF} sampling is a method for obtaining samples
from both discrete and continuous probability distributions
that requires the CDF to be invertable. The method assumes values of the CDF are Uniform random variables on [0, 1].
CDF values are generated and used as input into the inverted CDF to obain samples with the distribution defined by the CDF.

% ------------------------------------------------------------------------------------------------
% Sampling discrete distributions
% ------------------------------------------------------------------------------------------------
\ifblog
<h2>Sampling Discrete Distributions</h2>
\fi
\iftex
\section{Sampling Discrete Distributions}
\fi

A discrete probability distribution consisting of a finite set of $N$ probability values is defined by,
$\{p_i\}_N = \{p_1, p_2,\ldots,p_N\}$ with $p_i \geq 0, \forall i$ and $\sum_{i=1}^N{p_i} = 1.$ The CDF specifies the probability
that $i \leq n$ and is given by,
\begin{equation}
\label{eq:discrete_cdf}
P(i \leq n)=P(n)=\sum_{i=1}^n{p_i},
\end{equation}
where $P(N)=1.$

For a given generated CDF value, $u$, Equation (\ref{eq:discrete_cdf}) can always be inverted by evaluating it for each $n$ and
searching for the value of $n$ that satisfies, $P(n) \geq u.$ It can be seen that the generated samples will have
distribution $\{p_i\}_N$ since the intervals $P(n)-P(n-1) = p_n$ are Uniformly sampled.

Consider the distribution,

\begin{equation} 
\left\{\frac{1}{12}, \frac{1}{12}, \frac{1}{6}, \frac{1}{6}, \frac{1}{12}, \frac{5}{12} \right\}
\label{eq:discrete}
\end{equation}

It is shown in the following plot with its CDF.

\ifblog
\image{width = 600}{https://gly.fish/wp-content/uploads/posts/inverse-cdf-sampling/discrete_cdf.png}{\homedir/Develop/python/gly.fish/assets/posts/inverse_cdf_sampling/discrete_cdf.png}
\fi
\iftex
\image{width = 400}{https://gly.fish/wp-content/uploads/posts/inverse-cdf-sampling/discrete_cdf.png}{\homedir/Develop/python/gly.fish/assets/posts/inverse_cdf_sampling/discrete_cdf.png}
\fi

A sampler using the Inverse CDF method on the distribution $\{p_i\}_N$ implemented in Python is shown below.
The program first stores the CDF computed from each of the sums $P(n)$ in an array. Next, CDF samples using a $\textbf{Uniform}(0, 1)$ sampler are generated.
Finally, for each sampled CDF value, $u$, the array containing $P(n)$ is scanned for the value of $n$ where $P(n) \geq u$. The resulting values of $n$
will have the distribution $\{p_i\}_N$.

% Sampler code examples
\ifblog
<pre class="EnlighterJSRAW" data-enlighter-language="python">
import numpy

n = 10000
df = numpy.array([1/12, 1/12, 1/6, 1/6, 1/12, 5/12])
cdf = numpy.cumsum(df)

samples = [numpy.flatnonzero(cdf >= u)[0] for u in numpy.random.rand(n)]
</pre>
\fi

\iftex
\pagebreak
\begin{minted}[mathescape, frame=lines, framesep=2mm, fontsize=\footnotesize]{python}
import numpy

n = 10000
df = numpy.array([1/12, 1/12, 1/6, 1/6, 1/12, 5/12])
cdf = numpy.cumsum(df)

samples = [numpy.flatnonzero(cdf >= u)[0] for u in numpy.random.rand(n)]
\end{minted}
\fi

The figure below favorably compares generated samples and distribution (\ref{eq:discrete}),
\ifblog
\image{width = 600}{https://gly.fish/wp-content/uploads/posts/inverse-cdf-sampling/discrete_sampled_distribution.png}{\homedir/Develop/python/gly.fish/assets/posts/inverse_cdf_sampling/discrete_sampled_distribution.png}
\fi
\iftex
\image{width = 400}{https://gly.fish/wp-content/uploads/posts/inverse-cdf-sampling/discrete_sampled_distribution.png}{\homedir/Develop/python/gly.fish/assets/posts/inverse_cdf_sampling/discrete_sampled_distribution.png}
\fi


% multinomial sampling
\ifblog
It is also possible to directly sample $\{p_n\}$ using the <code>multinomial</code> sampler from
<code>numpy</code>,

<pre class="EnlighterJSRAW" data-enlighter-language="python">
import numpy

n = 10000
df = numpy.array([1/12, 1/12, 1/6, 1/6, 1/12, 5/12])
samples = numpy.random.multinomial(n, df, size=1)/n
</pre>
\fi

\iftex
It is also possible to directly sample $\{p_n\}$ using the \mintinline{python}{multinomial} sampler from
\mintinline{python}{numpy},

\begin{minted}[mathescape, frame=lines, framesep=2mm,fontsize=\footnotesize]{python}
import numpy

n = 10000
df = numpy.array([1/12, 1/12, 1/6, 1/6, 1/12, 5/12])
samples = numpy.random.multinomial(n, df, size=1)/n
\end{minted}
\fi

% ------------------------------------------------------------------------------------------------
% Sampling continuous distributions
% ------------------------------------------------------------------------------------------------
\ifblog
<h2>Sampling Continuous Distributions</h2>
\fi
\iftex
\section{Sampling Continuous Distributions}
\fi

A continuous probability distribution is defined by the  \href{https://en.wikipedia.org/wiki/Probability_density_function}{PDF},
$f_X(x)$, where $f_X(x) \geq 0, \forall x$ and $\int f_X(x) dx = 1.$ The CDF is a monotonically increasing function
that specifies the probability that $X \leq x$, namely,
\begin{equation}
\label{eq:continuous_cdf}
P(X \leq x) = F_X(x) = \int^{x} f_X(w) dw.
\end{equation}

% ------------------------------------------------------------------------------------------------
% Proof continuous distribution
% ------------------------------------------------------------------------------------------------
\ifblog
<h3>Proof</h3>
\fi
\iftex
\subsection{Proof}
\fi

To prove that Inverse CDF sampling works for continuos distributions it must be shown that,

\begin{equation}
\label{eq:continuous_proof}
P[F_X^{-1}(U) \leq x] = F_X(x),
\end{equation}

where $F_X^{-1}(x)$ is the inverse of $F_X(x)$ and $U \sim \textbf{Uniform}(0, 1)$. A more general result needed to complete
this proof is obtained using a change of variables on a CDF. If $Y=G(X)$ is a monotonically increasing invertable function of $X$ then
\begin{equation}
\label{eq:CDF_invariance}
P(X \leq x) = P(Y \leq y) = P[G(X) \leq G(x)].
\end{equation}

To prove this note that $G(x)$ is monotonically increasing so the ordering of values is preserved,

$$ X \le x \implies G(X) \le G(x).$$

Consequently, the order of the integration limits is maintained by the transformation. Futher, since $G(x)$ is invertable,
$x = G^{-1}(y)$ and $dx = \frac{dG^{-1}}{dy} dy$, so

$$
\begin{aligned}
P(X \leq x) & = \int^{x} f_X(w) dw \\
& = \int^{y} f_X(G^{-1}(z)) \frac{dG^{-1}}{dz} dz \\
& = \int^{y} f_Y(z) dz \\
& = P(Y \leq y) \\
& = P[G(X) \leq G(x)],
\end{aligned}
$$

where,

$$ f_Y(y) = f_X(G^{-1}(y)) \frac{dG^{-1}}{dy} $$

The proof of Equation (\ref{eq:continuous_proof}) follows from Equation (\ref{eq:CDF_invariance}), using $f_U(u) = 1$
since $U \sim \textbf{Uniform}(0, 1),$

$$
\begin{aligned}
P[F_X^{-1}(U) \leq x] & = P[F_X(F_X^{-1}(U)) \leq F_X(x)] \\
& = P[U \leq F_X(x)] \\
& = \int_{0}^{F_X(x)} f_U(w) dw \\
& = \int_{0}^{F_X(x)} dw \\
& = F_X(x).
\end{aligned}
$$

% ------------------------------------------------------------------------------------------------
% Example continuous distribution
% ------------------------------------------------------------------------------------------------
\ifblog
<h3>Example</h3>
\fi
\iftex
\subsection{Example}
\fi

Consider the \href{https://en.wikipedia.org/wiki/Weibull_distribution}{Weibull Distribution}, with density

\begin{equation}
\label{eq:Weibull_distribution}
f_X(x; k, \lambda) =
\begin{cases}
\frac{k}{\lambda}\left(\frac{x}{\lambda} \right)^{k-1} e^{\left(\frac{-x}{\lambda}\right)^k} & x \geq 0 \\
0 & x lt 0,
\end{cases}
\end{equation}

where $k$ is the shape parameter and $\lambda$ the scale parameter. The CDF is given by,

\begin{equation}
\label{eq:Weibull_cdf}
F_X(x; k, \lambda) =
\begin{cases}
1-e^{\left(\frac{-x}{\lambda}\right)^k} & x \geq 0 \\
0 & x < 0.
\end{cases}
\end{equation}

The CDF can be inverted to yield,

\begin{equation}
\label{eq:Weibull_inverse_cdf}
F_X^{-1}(u; k, \lambda) =
\begin{cases}
\lambda\ln\left(\frac{1}{1-u}\right)^{\frac{1}{k}} & 0 \leq u \geq 1 \\
0 & u < 0 \text{ or } u > 1.
\end{cases}
\end{equation}

In the example described here it will be assumed that $k=5.0$ and $\lambda=1.0$. The following plot shows the PDF and CDF using these values.
\ifblog
\image{width = 600}{https://gly.fish/wp-content/uploads/posts/inverse-cdf-sampling/weibull_cdf.png}{\homedir/Develop/python/gly.fish/assets/posts/inverse_cdf_sampling/weibull_cdf.png}
\fi
\iftex
\image{width = 400}{https://gly.fish/wp-content/uploads/posts/inverse-cdf-sampling/weibull_cdf.png}{\homedir/Develop/python/gly.fish/assets/posts/inverse_cdf_sampling/weibull_cdf.png}
\fi

The sampler implementaion for the continuous case is simpler than for the discrete case. Just as in the discrete case CDF samples with distribution
$\textbf{Uniform}(0, 1)$ are generated. The desired samples with the Wiebull distribution are then computed using the CDF inverse. Below an implementaion of the
sampler in Python is listed.

\ifblog
<pre class="EnlighterJSRAW" data-enlighter-language="python">
import numpy

k = 5.0
λ = 1.0
nsamples = 100000

cdf_inv = lambda u: λ * (numpy.log(1.0/(1.0 - u)))**(1.0/k)
samples = [cdf_inv(u) for u in numpy.random.rand(nsamples)]
</pre>
\fi

\iftex
\begin{minted}[mathescape, frame=lines, framesep=2mm,fontsize=\footnotesize]{python}
import numpy

k = 5.0
l = 1.0
nsamples = 100000

cdf_inv = lambda u: l * (numpy.log(1.0/(1.0 - u)))**(1.0/k)
samples = [cdf_inv(u) for u in numpy.random.rand(nsamples)]
\end{minted}
\fi

\ifblog
\image{width = 600}{https://gly.fish/wp-content/uploads/posts/inverse-cdf-sampling/weibull_sampled_distribution.png}{\homedir/Develop/python/gly.fish/assets/posts/inverse_cdf_sampling/weibull_sampled_distribution.png}
\fi
\iftex
\image{width = 400}{https://gly.fish/wp-content/uploads/posts/inverse-cdf-sampling/weibull_sampled_distribution.png}{\homedir/Develop/python/gly.fish/assets/posts/inverse_cdf_sampling/weibull_sampled_distribution.png}
\fi

\ifblog
\image{width = 600}{https://gly.fish/wp-content/uploads/posts/inverse-cdf-sampling/weibull_sampled_mean_convergence.png}{\homedir/Develop/python/gly.fish/assets/posts/inverse_cdf_sampling/weibull_sampled_mean_convergence.png}
\fi
\iftex
\image{width = 400}{https://gly.fish/wp-content/uploads/posts/inverse-cdf-sampling/weibull_sampled_mean_convergence.png}{\homedir/Develop/python/gly.fish/assets/posts/inverse_cdf_sampling/weibull_sampled_mean_convergence.png}
\fi

\ifblog
\image{width = 600}{https://gly.fish/wp-content/uploads/posts/inverse-cdf-sampling/weibull_sampled_std_convergence.png}{\homedir/Develop/python/gly.fish/assets/posts/inverse_cdf_sampling/weibull_sampled_std_convergence.png}
\fi
\iftex
\image{width = 400}{https://gly.fish/wp-content/uploads/posts/inverse-cdf-sampling/weibull_sampled_std_convergence.png}{\homedir/Develop/python/gly.fish/assets/posts/inverse_cdf_sampling/weibull_sampled_std_convergence.png}
\fi

\end{document}
